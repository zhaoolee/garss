import feedparser
import time
import os
import re
import pytz
from datetime import datetime
import yagmail
import requests
import markdown
import json
import shutil
from urllib.parse import urlparse
from multiprocessing import Pool,  Manager


def get_rss_info(feed_url, index, rss_info_list):
    result = {"result": []}
    request_success = False
    # å¦‚æœè¯·æ±‚å‡ºé”™,åˆ™é‡æ–°è¯·æ±‚,æœ€å¤šäº”æ¬¡
    for i in range(3):
        if(request_success == False):
            try:
                headers = {
                    # è®¾ç½®ç”¨æˆ·ä»£ç†å¤´(ä¸ºç‹¼æŠ«ä¸Šç¾Šçš®)
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36",
                    "Content-Encoding": "gzip"
                }
                # ä¸‰æ¬¡åˆ†åˆ«è®¾ç½®5, 10, 15ç§’é’Ÿè¶…æ—¶
                feed_url_content = requests.get(feed_url,  timeout= (i+1)*5 ,headers = headers).content
                feed = feedparser.parse(feed_url_content)
                feed_entries = feed["entries"]
                feed_entries_length = len(feed_entries)
                print("==feed_url=>>", feed_url, "==len=>>", feed_entries_length)
                for entrie in feed_entries[0: feed_entries_length-1]:
                    title = entrie["title"]
                    link = entrie["link"]
                    date = time.strftime("%Y-%m-%d", entrie["published_parsed"])

                    title = title.replace("\n", "")
                    title = title.replace("\r", "")

                    title = title.replace("|", "\|")
                    title = title.replace("[", "\[")
                    title = title.replace("]", "\]")



                    result["result"].append({
                        "title": title,
                        "link": link,
                        "date": date
                    })
                request_success = True
            except Exception as e:
                print(feed_url+"ç¬¬+"+str(i)+"+æ¬¡è¯·æ±‚å‡ºé”™==>>",e)
                pass
        else:
            pass

    rss_info_list[index] = result["result"]
    print("æœ¬æ¬¡çˆ¬å–==ã€‹ã€‹", feed_url, "<<<===", index, result["result"])
    # å‰©ä½™æ•°é‡
    remaining_amount = 0

    for tmp_rss_info_atom in rss_info_list:
        if(isinstance(tmp_rss_info_atom, int)):
            remaining_amount = remaining_amount + 1
            
    print("å½“å‰è¿›åº¦ | å‰©ä½™æ•°é‡", remaining_amount, "å·²å®Œæˆ==>>", len(rss_info_list)-remaining_amount)
    return result["result"]
    


def send_mail(email, title, contents):
    # åˆ¤æ–­secret.jsonæ˜¯å¦å­˜åœ¨
    user = ""
    password = ""
    host = ""
    try:
        if(os.environ["USER"]):
            user = os.environ["USER"]
        if(os.environ["PASSWORD"]):
            password = os.environ["PASSWORD"]
        if(os.environ["HOST"]):
            host = os.environ["HOST"]
    except:
        print("æ— æ³•è·å–githubçš„secretsé…ç½®ä¿¡æ¯,å¼€å§‹ä½¿ç”¨æœ¬åœ°å˜é‡")
        if(os.path.exists(os.path.join(os.getcwd(),"secret.json"))):
            with open(os.path.join(os.getcwd(),"secret.json"),'r') as load_f:
                load_dict = json.load(load_f)
                user = load_dict["user"]
                password = load_dict["password"]
                host = load_dict["host"]
                # print(load_dict)
        else:
            print("æ— æ³•è·å–å‘ä»¶äººä¿¡æ¯")
    
    # è¿æ¥é‚®ç®±æœåŠ¡å™¨
    # yag = yagmail.SMTP(user=user, password=password, host=host)
    yag = yagmail.SMTP(user = user, password = password, host=host)
    # å‘é€é‚®ä»¶
    yag.send(email, title, contents)

def replace_readme():
    new_edit_readme_md = [""]
    current_date_news_index = [""]
    
    # è¯»å–EditREADME.md
    print("replace_readme")
    new_num = 0
    with open(os.path.join(os.getcwd(),"EditREADME.md"),'r') as load_f:
        edit_readme_md = load_f.read();
        new_edit_readme_md[0] = edit_readme_md
        before_info_list =  re.findall(r'\{\{latest_content\}\}.*\[è®¢é˜…åœ°å€\]\(.*\)' ,edit_readme_md);
        # å¡«å……ç»Ÿè®¡RSSæ•°é‡
        new_edit_readme_md[0] = new_edit_readme_md[0].replace("{{rss_num}}", str(len(before_info_list)))
        # å¡«å……ç»Ÿè®¡æ—¶é—´
        ga_rss_datetime = datetime.fromtimestamp(int(time.time()),pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        new_edit_readme_md[0] = new_edit_readme_md[0].replace("{{ga_rss_datetime}}", str(ga_rss_datetime))

        # ä½¿ç”¨è¿›ç¨‹æ± è¿›è¡Œæ•°æ®è·å–ï¼Œè·å¾—rss_info_list

        

        
        before_info_list_len = len(before_info_list)
        rss_info_list = Manager().list(range(before_info_list_len))
        
        print('åˆå§‹åŒ–å®Œæ¯•==ã€‹', rss_info_list)

        

        # åˆ›å»ºä¸€ä¸ªæœ€å¤šå¼€å¯3è¿›ç¨‹çš„è¿›ç¨‹æ± 
        po = Pool(6)

        for index, before_info in enumerate(before_info_list):
            # è·å–link
            link = re.findall(r'\[è®¢é˜…åœ°å€\]\((.*)\)', before_info)[0]
            po.apply_async(get_rss_info,(link, index, rss_info_list))


        # å…³é—­è¿›ç¨‹æ± ,ä¸å†æ¥æ”¶æ–°çš„ä»»åŠ¡,å¼€å§‹æ‰§è¡Œä»»åŠ¡
        po.close()

        # ä¸»è¿›ç¨‹ç­‰å¾…æ‰€æœ‰å­è¿›ç¨‹ç»“æŸ
        po.join()
        print("----ç»“æŸ----", rss_info_list)


        for index, before_info in enumerate(before_info_list):
            # è·å–link
            link = re.findall(r'\[è®¢é˜…åœ°å€\]\((.*)\)', before_info)[0]
            # ç”Ÿæˆè¶…é“¾æ¥
            rss_info = rss_info_list[index]
            latest_content = ""
            parse_result = urlparse(link)
            scheme_netloc_url = str(parse_result.scheme)+"://"+str(parse_result.netloc)
            latest_content = "[æš‚æ— æ³•é€šè¿‡çˆ¬è™«è·å–ä¿¡æ¯, ç‚¹å‡»è¿›å…¥æºç½‘ç«™ä¸»é¡µ]("+ scheme_netloc_url +")"

            # åŠ å…¥åˆ°ç´¢å¼•
            try:
                for rss_info_atom in rss_info:
                    if (rss_info_atom["date"] == datetime.today().strftime("%Y-%m-%d")):
                        new_num = new_num + 1
                        current_date_news_index[0] = current_date_news_index[0] + "<div><a href='" + rss_info_atom["link"] + "' " + "style='line-height: 2; text-decoration: none; display: block;'>" + "ğŸŒˆ " + "â€£ " + rss_info_atom["title"] + " | ç¬¬" + str(new_num) +"ç¯‡" + "</a><div>"
            except:
                print("An exception occurred")
                
            if(len(rss_info) > 0):

                latest_content = "[" + "â€£ " + rss_info[0]["title"] + ( " ğŸŒˆ " + rss_info[0]["date"] if (rss_info[0]["date"] == datetime.today().strftime("%Y-%m-%d")) else " \| " + rss_info[0]["date"] ) +"](" + rss_info[0]["link"] +")"  

            if(len(rss_info) > 1):

                latest_content = latest_content + "<br/>[" + "â€£ " +  rss_info[1]["title"] + ( " ğŸŒˆ " + rss_info[0]["date"] if (rss_info[0]["date"] == datetime.today().strftime("%Y-%m-%d")) else " \| " + rss_info[0]["date"] ) +"](" + rss_info[1]["link"] +")"

            # ç”Ÿæˆafter_info
            after_info = before_info.replace("{{latest_content}}", latest_content)
            print("====latest_content==>", latest_content)
            # æ›¿æ¢edit_readme_mdä¸­çš„å†…å®¹
            new_edit_readme_md[0] = new_edit_readme_md[0].replace(before_info, after_info)
    
    # æ›¿æ¢EditREADMEä¸­çš„ç´¢å¼•
    new_edit_readme_md[0] = new_edit_readme_md[0].replace("{{news}}", current_date_news_index[0])
    # æ›¿æ¢EditREADMEä¸­çš„æ–°æ–‡ç« æ•°é‡ç´¢å¼•
    new_edit_readme_md[0] = new_edit_readme_md[0].replace("{{new_num}}", str(new_num))
    # æ·»åŠ CDN
    new_edit_readme_md[0] = new_edit_readme_md[0].replace("./_media", "https://cdn.jsdelivr.net/gh/zhaoolee/garss/_media")
        
    # å°†æ–°å†…å®¹
    with open(os.path.join(os.getcwd(),"README.md"),'w') as load_f:
        load_f.write(new_edit_readme_md[0])
    
    return new_edit_readme_md

# å°†README.mdå¤åˆ¶åˆ°docsä¸­

def cp_readme_md_to_docs():
    shutil.copyfile(os.path.join(os.getcwd(),"README.md"), os.path.join(os.getcwd(), "docs","README.md"))
    
def cp_media_to_docs():
    if os.path.exists(os.path.join(os.getcwd(), "docs","_media")):
        shutil.rmtree(os.path.join(os.getcwd(), "docs","_media"))	
    shutil.copytree(os.path.join(os.getcwd(),"_media"), os.path.join(os.getcwd(), "docs","_media"))

def get_email_list():
    email_list = []
    with open(os.path.join(os.getcwd(),"tasks.json"),'r') as load_f:
        load_dic = json.load(load_f)
        for task in load_dic["tasks"]:
            email_list.append(task["email"])
    return email_list



def main():
    readme_md = replace_readme()
    content = markdown.markdown(readme_md[0], extensions=['tables', 'fenced_code'])
    cp_readme_md_to_docs()
    cp_media_to_docs()
    email_list = get_email_list()
    try:
        send_mail(email_list, "å˜!RSSè®¢é˜…", content)
    except Exception as e:
        print("==é‚®ä»¶è®¾ä¿¡æ¯ç½®é”™è¯¯===ã€‹ã€‹", e)


if __name__ == "__main__":
    main()